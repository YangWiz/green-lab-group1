{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459083c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /Users/liuruyi/github/Green_Lab_group1/green-lab-group1/data-analysis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__run_id</th>\n",
       "      <th>__done</th>\n",
       "      <th>_compiler</th>\n",
       "      <th>_benchmark</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>energy_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>run_7_repetition_5</td>\n",
       "      <td>DONE</td>\n",
       "      <td>pure_python</td>\n",
       "      <td>regex</td>\n",
       "      <td>0.401</td>\n",
       "      <td>4.521</td>\n",
       "      <td>8537481.000</td>\n",
       "      <td>7.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run_17_repetition_19</td>\n",
       "      <td>DONE</td>\n",
       "      <td>cython</td>\n",
       "      <td>regex</td>\n",
       "      <td>0.401</td>\n",
       "      <td>6.899</td>\n",
       "      <td>8519287.000</td>\n",
       "      <td>7.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run_3_repetition_8</td>\n",
       "      <td>DONE</td>\n",
       "      <td>pure_python</td>\n",
       "      <td>fft</td>\n",
       "      <td>0.201</td>\n",
       "      <td>13.341</td>\n",
       "      <td>8496410.667</td>\n",
       "      <td>3.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run_16_repetition_11</td>\n",
       "      <td>DONE</td>\n",
       "      <td>cython</td>\n",
       "      <td>quick_sort</td>\n",
       "      <td>0.401</td>\n",
       "      <td>4.488</td>\n",
       "      <td>8508329.000</td>\n",
       "      <td>5.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run_28_repetition_19</td>\n",
       "      <td>DONE</td>\n",
       "      <td>swig</td>\n",
       "      <td>sieve</td>\n",
       "      <td>0.201</td>\n",
       "      <td>3.279</td>\n",
       "      <td>8518120.000</td>\n",
       "      <td>1.549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               __run_id __done    _compiler  _benchmark  execution_time  \\\n",
       "0    run_7_repetition_5   DONE  pure_python       regex           0.401   \n",
       "1  run_17_repetition_19   DONE       cython       regex           0.401   \n",
       "2    run_3_repetition_8   DONE  pure_python         fft           0.201   \n",
       "3  run_16_repetition_11   DONE       cython  quick_sort           0.401   \n",
       "4  run_28_repetition_19   DONE         swig       sieve           0.201   \n",
       "\n",
       "   cpu_usage  memory_usage  energy_consumption  \n",
       "0      4.521   8537481.000               7.214  \n",
       "1      6.899   8519287.000               7.261  \n",
       "2     13.341   8496410.667               3.896  \n",
       "3      4.488   8508329.000               5.935  \n",
       "4      3.279   8518120.000               1.549  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 0\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"cwd:\", os.getcwd())          # confirm current directory\n",
    "df = pd.read_csv(\"run_table.csv\")  # adjust path if necessary\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed91e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6854d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (600, 8)\n",
      "\n",
      "Compiler types: ['pure_python' 'cython' 'swig']\n",
      "\n",
      "Benchmark types: ['regex' 'fft' 'quick_sort' 'sieve' 'dense_matrix' 'nbody' 'convex'\n",
      " 'k_means' 'bfs' 'json_bench']\n"
     ]
    }
   ],
   "source": [
    "# Check basic data information\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nCompiler types:\", df['_compiler'].unique())\n",
    "print(\"\\nBenchmark types:\", df['_benchmark'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2fa0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_shapiro_wilk_testing(df):\n",
    "    \"\"\"\n",
    "    Perform Shapiro-Wilk normality tests for all (benchmark × compiler × metric) combinations\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    compilers = df['_compiler'].unique()\n",
    "    benchmarks = df['_benchmark'].unique()\n",
    "    metrics = ['execution_time', 'cpu_usage', 'memory_usage', 'energy_consumption']\n",
    "    \n",
    "    print(\"Performing Shapiro-Wilk normality tests for all combinations...\")\n",
    "    print(f\"Compilers: {list(compilers)}\")\n",
    "    print(f\"Benchmarks: {list(benchmarks)}\")\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    print(f\"Total combinations: {len(compilers)} × {len(benchmarks)} × {len(metrics)} = {len(compilers)*len(benchmarks)*len(metrics)}\")\n",
    "    print()\n",
    "    \n",
    "    for compiler in compilers:\n",
    "        for benchmark in benchmarks:\n",
    "            for metric in metrics:\n",
    "                # Get data for this specific combination\n",
    "                subset = df[(df['_compiler'] == compiler) & \n",
    "                           (df['_benchmark'] == benchmark)]\n",
    "                \n",
    "                values = subset[metric].dropna()\n",
    "                    \n",
    "                # Perform Shapiro-Wilk test\n",
    "                shapiro_stat, shapiro_p = stats.shapiro(values)\n",
    "                \n",
    "                # Calculate descriptive statistics\n",
    "                skew_val = stats.skew(values)\n",
    "                kurtosis_val = stats.kurtosis(values)\n",
    "                \n",
    "                results.append({\n",
    "                    'compiler': compiler,\n",
    "                    'benchmark': benchmark,\n",
    "                    'metric': metric,\n",
    "                    'sample_size': len(values),\n",
    "                    'shapiro_statistic': shapiro_stat,\n",
    "                    'shapiro_p_value': shapiro_p,\n",
    "                    'is_normal': shapiro_p > 0.05,\n",
    "                    'skewness': skew_val,\n",
    "                    'kurtosis': kurtosis_val,\n",
    "                    'mean': values.mean(),\n",
    "                    'std': values.std(),\n",
    "                    'min': values.min(),\n",
    "                    'max': values.max()\n",
    "                })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b5e22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_rq1(normality_df):\n",
    "    \"\"\"\n",
    "    RQ1: Energy Consumption - Python vs C++\n",
    "    Analyze normality for energy consumption across all compilers and benchmarks\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"RQ1 ANALYSIS: Energy Consumption Normality (Python vs C++)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Filter for energy consumption metric only\n",
    "    energy_data = normality_df[normality_df['metric'] == 'energy_consumption']\n",
    "    \n",
    "    # Group by compiler\n",
    "    compiler_groups = energy_data.groupby('compiler')\n",
    "    \n",
    "    rq1_results = {}\n",
    "    \n",
    "    for compiler, group in compiler_groups:\n",
    "        total_tests = len(group)\n",
    "        normal_tests = group['is_normal'].sum()\n",
    "        normal_ratio = normal_tests / total_tests\n",
    "        \n",
    "        rq1_results[compiler] = {\n",
    "            'total_tests': total_tests,\n",
    "            'normal_tests': normal_tests,\n",
    "            'normal_ratio': normal_ratio\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{compiler.upper():<12}: {normal_tests}/{total_tests} normal ({normal_ratio:.1%})\")\n",
    "        \n",
    "        # Breakdown by benchmark\n",
    "        print(\"  By Benchmark:\")\n",
    "        benchmark_groups = group.groupby('benchmark')\n",
    "        for benchmark, bench_group in benchmark_groups:\n",
    "            bench_normal = bench_group['is_normal'].sum()\n",
    "            bench_total = len(bench_group)\n",
    "            print(f\"    {benchmark:<15}: {bench_normal}/{bench_total} normal\")\n",
    "    \n",
    "    return rq1_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b5fa8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_rq2(normality_df):\n",
    "    \"\"\"\n",
    "    RQ2: Performance Metrics - Python vs C++\n",
    "    Analyze normality for execution_time, cpu_usage, memory_usage\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RQ2 ANALYSIS: Performance Metrics Normality (Python vs C++)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Filter for performance metrics only\n",
    "    performance_metrics = ['execution_time', 'cpu_usage', 'memory_usage']\n",
    "    perf_data = normality_df[normality_df['metric'].isin(performance_metrics)]\n",
    "    \n",
    "    rq2_results = {}\n",
    "    \n",
    "    # Analysis by compiler\n",
    "    print(\"Overall by Compiler:\")\n",
    "    compiler_groups = perf_data.groupby('compiler')\n",
    "    for compiler, group in compiler_groups:\n",
    "        total_tests = len(group)\n",
    "        normal_tests = group['is_normal'].sum()\n",
    "        normal_ratio = normal_tests / total_tests\n",
    "        \n",
    "        rq2_results[compiler] = {\n",
    "            'total_tests': total_tests,\n",
    "            'normal_tests': normal_tests,\n",
    "            'normal_ratio': normal_ratio\n",
    "        }\n",
    "        \n",
    "        print(f\"  {compiler.upper():<12}: {normal_tests}/{total_tests} normal ({normal_ratio:.1%})\")\n",
    "    \n",
    "    # Analysis by metric\n",
    "    print(\"\\nBy Metric (across all compilers):\")\n",
    "    metric_groups = perf_data.groupby('metric')\n",
    "    for metric, group in metric_groups:\n",
    "        total_tests = len(group)\n",
    "        normal_tests = group['is_normal'].sum()\n",
    "        normal_ratio = normal_tests / total_tests\n",
    "        \n",
    "        print(f\"  {metric:<15}: {normal_tests}/{total_tests} normal ({normal_ratio:.1%})\")\n",
    "        \n",
    "        # Breakdown by compiler for this metric\n",
    "        metric_compiler_groups = group.groupby('compiler')\n",
    "        for compiler, compiler_group in metric_compiler_groups:\n",
    "            comp_normal = compiler_group['is_normal'].sum()\n",
    "            comp_total = len(compiler_group)\n",
    "            print(f\"    {compiler:<12}: {comp_normal}/{comp_total} normal\")\n",
    "    \n",
    "    return rq2_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0982607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_rq3(normality_df):\n",
    "    \"\"\"\n",
    "    RQ3: Energy Consumption - Cython vs SWIG\n",
    "    Analyze normality for energy consumption comparing only Cython and SWIG\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RQ3 ANALYSIS: Energy Consumption Normality (Cython vs SWIG)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Filter for energy consumption and only Cython/SWIG\n",
    "    energy_data = normality_df[\n",
    "        (normality_df['metric'] == 'energy_consumption') & \n",
    "        (normality_df['compiler'].isin(['cython', 'swig']))\n",
    "    ]\n",
    "    \n",
    "    rq3_results = {}\n",
    "    \n",
    "    compiler_groups = energy_data.groupby('compiler')\n",
    "    \n",
    "    for compiler, group in compiler_groups:\n",
    "        total_tests = len(group)\n",
    "        normal_tests = group['is_normal'].sum()\n",
    "        normal_ratio = normal_tests / total_tests\n",
    "        \n",
    "        rq3_results[compiler] = {\n",
    "            'total_tests': total_tests,\n",
    "            'normal_tests': normal_tests,\n",
    "            'normal_ratio': normal_ratio\n",
    "        }\n",
    "        \n",
    "        print(f\"{compiler.upper():<12}: {normal_tests}/{total_tests} normal ({normal_ratio:.1%})\")\n",
    "    \n",
    "    return rq3_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a41b19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_rq4(normality_df):\n",
    "    \"\"\"\n",
    "    RQ4: Performance Metrics - Cython vs SWIG\n",
    "    Analyze normality for performance metrics comparing only Cython and SWIG\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RQ4 ANALYSIS: Performance Metrics Normality (Cython vs SWIG)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Filter for performance metrics and only Cython/SWIG\n",
    "    performance_metrics = ['execution_time', 'cpu_usage', 'memory_usage']\n",
    "    perf_data = normality_df[\n",
    "        normality_df['metric'].isin(performance_metrics) & \n",
    "        normality_df['compiler'].isin(['cython', 'swig'])\n",
    "    ]\n",
    "    \n",
    "    rq4_results = {}\n",
    "    \n",
    "    # Analysis by compiler\n",
    "    print(\"Overall by Compiler:\")\n",
    "    compiler_groups = perf_data.groupby('compiler')\n",
    "    for compiler, group in compiler_groups:\n",
    "        total_tests = len(group)\n",
    "        normal_tests = group['is_normal'].sum()\n",
    "        normal_ratio = normal_tests / total_tests\n",
    "        \n",
    "        rq4_results[compiler] = {\n",
    "            'total_tests': total_tests,\n",
    "            'normal_tests': normal_tests,\n",
    "            'normal_ratio': normal_ratio\n",
    "        }\n",
    "        \n",
    "        print(f\"  {compiler.upper():<12}: {normal_tests}/{total_tests} normal ({normal_ratio:.1%})\")\n",
    "    \n",
    "    # Analysis by metric for Cython/SWIG only\n",
    "    print(\"\\nBy Metric (Cython and SWIG only):\")\n",
    "    for metric in performance_metrics:\n",
    "        metric_data = perf_data[perf_data['metric'] == metric]\n",
    "        total_tests = len(metric_data)\n",
    "        normal_tests = metric_data['is_normal'].sum()\n",
    "        normal_ratio = normal_tests / total_tests\n",
    "        \n",
    "        print(f\"  {metric:<15}: {normal_tests}/{total_tests} normal ({normal_ratio:.1%})\")\n",
    "    \n",
    "    return rq4_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f16bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_final_recommendations(rq1_results, rq2_results, rq3_results, rq4_results):\n",
    "    \"\"\"\n",
    "    Generate final test method recommendations based on normality results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"FINAL STATISTICAL TEST RECOMMENDATIONS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Overall recommendation based on majority\n",
    "    all_normal_ratios = []\n",
    "    \n",
    "    # Collect all normal ratios\n",
    "    for rq_results in [rq1_results, rq2_results, rq3_results, rq4_results]:\n",
    "        for compiler, data in rq_results.items():\n",
    "            all_normal_ratios.append(data['normal_ratio'])\n",
    "    \n",
    "    overall_normal_ratio = np.mean(all_normal_ratios)\n",
    "    \n",
    "    print(f\"Overall normal distribution ratio: {overall_normal_ratio:.1%}\")\n",
    "    \n",
    "    if overall_normal_ratio > 0.5:\n",
    "        print(\"RECOMMENDATION: Use PARAMETRIC tests (paired t-tests)\")\n",
    "        primary_method = \"parametric\"\n",
    "    else:\n",
    "        print(\"RECOMMENDATION: Use NON-PARAMETRIC tests (permutation tests)\")\n",
    "        primary_method = \"non-parametric\"\n",
    "    \n",
    "    # Detailed recommendations for each RQ\n",
    "    print(\"\\nDetailed Recommendations by Research Question:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    recommendations = {\n",
    "        'RQ1': {},\n",
    "        'RQ2': {}, \n",
    "        'RQ3': {},\n",
    "        'RQ4': {}\n",
    "    }\n",
    "    \n",
    "    # RQ1 recommendations\n",
    "    rq1_normal_ratio = np.mean([data['normal_ratio'] for data in rq1_results.values()])\n",
    "    recommendations['RQ1']['method'] = 'parametric' if rq1_normal_ratio > 0.5 else 'permutation'\n",
    "    recommendations['RQ1']['normal_ratio'] = rq1_normal_ratio\n",
    "    \n",
    "    # RQ2 recommendations  \n",
    "    rq2_normal_ratio = np.mean([data['normal_ratio'] for data in rq2_results.values()])\n",
    "    recommendations['RQ2']['method'] = 'parametric' if rq2_normal_ratio > 0.5 else 'permutation'\n",
    "    recommendations['RQ2']['normal_ratio'] = rq2_normal_ratio\n",
    "    \n",
    "    # RQ3 recommendations\n",
    "    rq3_normal_ratio = np.mean([data['normal_ratio'] for data in rq3_results.values()])\n",
    "    recommendations['RQ3']['method'] = 'parametric' if rq3_normal_ratio > 0.5 else 'permutation'\n",
    "    recommendations['RQ3']['normal_ratio'] = rq3_normal_ratio\n",
    "    \n",
    "    # RQ4 recommendations\n",
    "    rq4_normal_ratio = np.mean([data['normal_ratio'] for data in rq4_results.values()])\n",
    "    recommendations['RQ4']['method'] = 'parametric' if rq4_normal_ratio > 0.5 else 'permutation'\n",
    "    recommendations['RQ4']['normal_ratio'] = rq4_normal_ratio\n",
    "    \n",
    "    for rq, rec in recommendations.items():\n",
    "        print(f\"{rq}: {rec['method'].upper()} tests (normal ratio: {rec['normal_ratio']:.1%})\")\n",
    "    \n",
    "    return recommendations, primary_method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb60f339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Shapiro-Wilk normality tests for all combinations...\n",
      "Compilers: ['pure_python', 'cython', 'swig']\n",
      "Benchmarks: ['regex', 'fft', 'quick_sort', 'sieve', 'dense_matrix', 'nbody', 'convex', 'k_means', 'bfs', 'json_bench']\n",
      "Metrics: ['execution_time', 'cpu_usage', 'memory_usage', 'energy_consumption']\n",
      "Total combinations: 3 × 10 × 4 = 120\n",
      "\n",
      "\n",
      "Detailed normality results saved to 'comprehensive_normality_results.csv'\n",
      "Total normality tests performed: 120\n",
      "======================================================================\n",
      "RQ1 ANALYSIS: Energy Consumption Normality (Python vs C++)\n",
      "======================================================================\n",
      "\n",
      "CYTHON      : 2/10 normal (20.0%)\n",
      "  By Benchmark:\n",
      "    bfs            : 0/1 normal\n",
      "    convex         : 0/1 normal\n",
      "    dense_matrix   : 0/1 normal\n",
      "    fft            : 0/1 normal\n",
      "    json_bench     : 0/1 normal\n",
      "    k_means        : 1/1 normal\n",
      "    nbody          : 1/1 normal\n",
      "    quick_sort     : 0/1 normal\n",
      "    regex          : 0/1 normal\n",
      "    sieve          : 0/1 normal\n",
      "\n",
      "PURE_PYTHON : 5/10 normal (50.0%)\n",
      "  By Benchmark:\n",
      "    bfs            : 0/1 normal\n",
      "    convex         : 1/1 normal\n",
      "    dense_matrix   : 0/1 normal\n",
      "    fft            : 0/1 normal\n",
      "    json_bench     : 0/1 normal\n",
      "    k_means        : 0/1 normal\n",
      "    nbody          : 1/1 normal\n",
      "    quick_sort     : 1/1 normal\n",
      "    regex          : 1/1 normal\n",
      "    sieve          : 1/1 normal\n",
      "\n",
      "SWIG        : 2/10 normal (20.0%)\n",
      "  By Benchmark:\n",
      "    bfs            : 0/1 normal\n",
      "    convex         : 0/1 normal\n",
      "    dense_matrix   : 0/1 normal\n",
      "    fft            : 1/1 normal\n",
      "    json_bench     : 0/1 normal\n",
      "    k_means        : 0/1 normal\n",
      "    nbody          : 1/1 normal\n",
      "    quick_sort     : 0/1 normal\n",
      "    regex          : 0/1 normal\n",
      "    sieve          : 0/1 normal\n",
      "\n",
      "======================================================================\n",
      "RQ2 ANALYSIS: Performance Metrics Normality (Python vs C++)\n",
      "======================================================================\n",
      "Overall by Compiler:\n",
      "  CYTHON      : 11/30 normal (36.7%)\n",
      "  PURE_PYTHON : 16/30 normal (53.3%)\n",
      "  SWIG        : 10/30 normal (33.3%)\n",
      "\n",
      "By Metric (across all compilers):\n",
      "  cpu_usage      : 8/30 normal (26.7%)\n",
      "    cython      : 1/10 normal\n",
      "    pure_python : 6/10 normal\n",
      "    swig        : 1/10 normal\n",
      "  execution_time : 0/30 normal (0.0%)\n",
      "    cython      : 0/10 normal\n",
      "    pure_python : 0/10 normal\n",
      "    swig        : 0/10 normal\n",
      "  memory_usage   : 29/30 normal (96.7%)\n",
      "    cython      : 10/10 normal\n",
      "    pure_python : 10/10 normal\n",
      "    swig        : 9/10 normal\n",
      "\n",
      "======================================================================\n",
      "RQ3 ANALYSIS: Energy Consumption Normality (Cython vs SWIG)\n",
      "======================================================================\n",
      "CYTHON      : 2/10 normal (20.0%)\n",
      "SWIG        : 2/10 normal (20.0%)\n",
      "\n",
      "======================================================================\n",
      "RQ4 ANALYSIS: Performance Metrics Normality (Cython vs SWIG)\n",
      "======================================================================\n",
      "Overall by Compiler:\n",
      "  CYTHON      : 11/30 normal (36.7%)\n",
      "  SWIG        : 10/30 normal (33.3%)\n",
      "\n",
      "By Metric (Cython and SWIG only):\n",
      "  execution_time : 0/20 normal (0.0%)\n",
      "  cpu_usage      : 2/20 normal (10.0%)\n",
      "  memory_usage   : 19/20 normal (95.0%)\n",
      "\n",
      "======================================================================\n",
      "FINAL STATISTICAL TEST RECOMMENDATIONS\n",
      "======================================================================\n",
      "Overall normal distribution ratio: 32.3%\n",
      "RECOMMENDATION: Use NON-PARAMETRIC tests (permutation tests)\n",
      "\n",
      "Detailed Recommendations by Research Question:\n",
      "--------------------------------------------------\n",
      "RQ1: PERMUTATION tests (normal ratio: 30.0%)\n",
      "RQ2: PERMUTATION tests (normal ratio: 41.1%)\n",
      "RQ3: PERMUTATION tests (normal ratio: 20.0%)\n",
      "RQ4: PERMUTATION tests (normal ratio: 35.0%)\n",
      "\n",
      "Analysis complete! Primary method recommendation: NON-PARAMETRIC tests\n"
     ]
    }
   ],
   "source": [
    "# Perform comprehensive normality testing\n",
    "normality_results = comprehensive_shapiro_wilk_testing(df)\n",
    "\n",
    "# Save detailed results\n",
    "normality_results.to_csv('comprehensive_normality_results.csv', index=False)\n",
    "print(f\"\\nDetailed normality results saved to 'comprehensive_normality_results.csv'\")\n",
    "print(f\"Total normality tests performed: {len(normality_results)}\")\n",
    "\n",
    "# Analyze each research question\n",
    "rq1_results = analyze_rq1(normality_results)\n",
    "rq2_results = analyze_rq2(normality_results) \n",
    "rq3_results = analyze_rq3(normality_results)\n",
    "rq4_results = analyze_rq4(normality_results)\n",
    "\n",
    "# Generate final recommendations\n",
    "recommendations, primary_method = generate_final_recommendations(\n",
    "    rq1_results, rq2_results, rq3_results, rq4_results\n",
    ")\n",
    "\n",
    "# Save summary report\n",
    "summary_report = {\n",
    "    'total_tests': len(normality_results),\n",
    "    'overall_normal_ratio': normality_results['is_normal'].mean(),\n",
    "    'primary_method': primary_method,\n",
    "    'rq1_results': rq1_results,\n",
    "    'rq2_results': rq2_results,\n",
    "    'rq3_results': rq3_results, \n",
    "    'rq4_results': rq4_results,\n",
    "    'recommendations': recommendations\n",
    "}\n",
    "\n",
    "print(f\"\\nAnalysis complete! Primary method recommendation: {primary_method.upper()} tests\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenlab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
